{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9aHTrpANhSoC"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAnqNAzfcVu0"
   },
   "source": [
    "# Emotion prediction with GoEmotions and PRADO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcNoWgG7hvIs"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/models/blob/master/research/seq_flow_lite/demo/colab/emotion_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/research/seq_flow_lite/demo/colab/emotion_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhekoIrWiSsv"
   },
   "source": [
    "In this tutorial, we will work through training a neural emotion prediction model, using the tensorflow-models PIP package, and Bazel.\n",
    "\n",
    "This tutorial is using GoEmotions, an emotion prediction dataset, available on [TensorFlow TFDS](https://www.tensorflow.org/datasets/catalog/goemotions). We will be training a sequence projection model architecture named PRADO, available on [TensorFlow Model Garden](https://github.com/tensorflow/models/blob/master/research/seq_flow_lite/models/prado.py). Finally, we will examine an application of emotion prediction to emoji suggestions from text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grmac7ZYj02a"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aGnloeD1Mfo"
   },
   "source": [
    "### Install Tensorflow 2.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqP5qpAR1W4f"
   },
   "source": [
    "The seq_flow_lite library has been written with the assumption that tensorflow 2.11.0 will be used.  It may be necessary to restart the runtime after installing the correct version of Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzuq_GVn1nXO"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_mi4NZeeB1l"
   },
   "source": [
    "### Install the TensorFlow Datasets pip package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCk46-HdmIyD"
   },
   "source": [
    "`tensorflow_datasets` is a set of collection of datasets that includes the GoEmotions dataset. We install it with pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvO0_HcKx0_V"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2wqyg-7mbfV"
   },
   "source": [
    "### Install the Sequence Projection Models package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JRZS_aSeINK"
   },
   "source": [
    "Install Bazel: This will allow us to build custom TensorFlow ops used by the PRADO architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N00X4P229Ppm"
   },
   "outputs": [],
   "source": [
    "!sudo apt install curl gnupg\n",
    "!curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -\n",
    "!echo \"deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\" | sudo tee /etc/apt/sources.list.d/bazel.list\n",
    "!sudo apt update\n",
    "!sudo apt install bazel=5.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JeSDpZFelL5"
   },
   "source": [
    "Install the library:\n",
    "* `seq_flow_lite` includes the PRADO architecture and custom ops.\n",
    "* We download the code from GitHub, and then build and install the TF and TFLite ops used by the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mktlCYcd9iLG"
   },
   "outputs": [],
   "source": [
    "!git clone https://www.github.com/tensorflow/models\n",
    "!models/research/seq_flow_lite/demo/colab/setup_workspace.sh\n",
    "!pip install models/research/seq_flow_lite\n",
    "!rm -rf models/research/seq_flow_lite/tf_ops\n",
    "!rm -rf models/research/seq_flow_lite/tflite_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rP8iKa4Il4mL"
   },
   "source": [
    "## Training an Emotion Prediction Model\n",
    "\n",
    "* First, we load the GoEmotions data from TFDS.\n",
    "* Next, we prepare the PRADO model for training. We set up the model configuration, including hyperparameters and labels. We also prepare the dataset, which involves projecting the inputs from the dataset, and passing the projections to the model.  This is needed because a model training on TPU can not handle string inputs.\n",
    "* Finally, we train and evaluate the model and produce model-level and per-label metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtvR40K8K0Bn"
   },
   "source": [
    "***Start here on Runtime reset***, once the packages above are properly installed:\n",
    "* Go to the `seq_flow_lite` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImEejssVKvxR"
   },
   "outputs": [],
   "source": [
    "%cd models/research/seq_flow_lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwSPqHXAeQ6H"
   },
   "source": [
    "* Import the Tensorflow and Tensorflow Dataset libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kc4y4n80eL_b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-CtG3cagPgl"
   },
   "source": [
    "### The data: GoEmotions\n",
    "In this tutorial, we use the [GoEmotions dataset from TFDS](https://www.tensorflow.org/datasets/catalog/goemotions).\n",
    "\n",
    "GoEmotions is a corpus of comments extracted from Reddit, with human annotations to 27 emotion categories or Neutral.\n",
    "\n",
    "*   Number of labels: 27.\n",
    "*   Size of training dataset: 43,410.\n",
    "*   Size of evaluation dataset: 5,427.\n",
    "*   Maximum sequence length in training and evaluation datasets: 30.\n",
    "\n",
    "The emotion categories are admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bvsn_s3S0SAt"
   },
   "source": [
    "Load the data from TFDS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtTLwtEqwcR2"
   },
   "outputs": [],
   "source": [
    "ds = tfds.load('goemotions', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJuu4jKet9zq"
   },
   "source": [
    "Print 5 sample data elements from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0O18rSLuDx5"
   },
   "outputs": [],
   "source": [
    "for element in ds.take(5):\n",
    "  print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAz-tdQfuVBn"
   },
   "source": [
    "### The model: PRADO\n",
    "\n",
    "We train an Emotion Prediction model, based on the [PRADO architecture](https://github.com/tensorflow/models/blob/master/research/seq_flow_lite/models/prado.py) from the [Sequence Projection Models package](https://github.com/tensorflow/models/tree/master/research/seq_flow_lite).\n",
    "\n",
    "PRADO projects input sequences to fixed sized features. The idea behind this approach is to build embedding-free models that minimize the model size. Instead of using an embedding table to lookup embeddings, sequence projection models compute them on the fly, resulting in space-efficient models.\n",
    "\n",
    "In this section, we prepare the PRADO model for training.\n",
    "\n",
    "This GoEmotions dataset is not set up so that it can be directly fed into the PRADO model, so below, we also handle the necessary preprocessing by providing a dataset builder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9uPSZYpgBqP"
   },
   "source": [
    "Prepare the model configuration:\n",
    "* Enumerate the labels expected to be found in the GoEmotions dataset.\n",
    "* Prepare the `MODEL_CONFIG` dictionary which includes training parameters for the model. See sample configs for the PRADO model [here](https://github.com/tensorflow/models/tree/master/research/seq_flow_lite/configs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkQMnTcLyFeR"
   },
   "outputs": [],
   "source": [
    "LABELS = [\n",
    "    'admiration',\n",
    "    'amusement',\n",
    "    'anger',\n",
    "    'annoyance',\n",
    "    'approval',\n",
    "    'caring',\n",
    "    'confusion',\n",
    "    'curiosity',\n",
    "    'desire',\n",
    "    'disappointment',\n",
    "    'disapproval',\n",
    "    'disgust',\n",
    "    'embarrassment',\n",
    "    'excitement',\n",
    "    'fear',\n",
    "    'gratitude',\n",
    "    'grief',\n",
    "    'joy',\n",
    "    'love',\n",
    "    'nervousness',\n",
    "    'optimism',\n",
    "    'pride',\n",
    "    'realization',\n",
    "    'relief',\n",
    "    'remorse',\n",
    "    'sadness',\n",
    "    'surprise',\n",
    "    'neutral',\n",
    "]\n",
    "\n",
    "# Model training parameters.\n",
    "CONFIG = {\n",
    "    'name': 'models.prado',\n",
    "    'batch_size': 1024,\n",
    "    'train_steps': 10000,\n",
    "    'learning_rate': 0.0006,\n",
    "    'learning_rate_decay_steps': 340,\n",
    "    'learning_rate_decay_rate': 0.7,\n",
    "}\n",
    "\n",
    "# Limits the amount of logging output produced by the training run, in order to\n",
    "# avoid browser slowdowns.\n",
    "CONFIG['save_checkpoints_steps'] = int(CONFIG['train_steps'] / 10)\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    'labels': LABELS,\n",
    "    'multilabel': True,\n",
    "    'quantize': False,\n",
    "    'max_seq_len': 128,\n",
    "    'max_seq_len_inference': 128,\n",
    "    'exclude_nonalphaspace_unicodes': False,\n",
    "    'split_on_space': True,\n",
    "    'embedding_regularizer_scale': 0.035,\n",
    "    'embedding_size': 64,\n",
    "    'bigram_channels': 64,\n",
    "    'trigram_channels': 64,\n",
    "    'feature_size': 512,\n",
    "    'network_regularizer_scale': 0.0001,\n",
    "    'keep_prob': 0.5,\n",
    "    'word_novelty_bits': 0,\n",
    "    'doc_size_levels': 0,\n",
    "    'add_bos_tag': False,\n",
    "    'add_eos_tag': False,\n",
    "    'pre_logits_fc_layers': [],\n",
    "    'text_distortion_probability': 0.0,\n",
    "}\n",
    "\n",
    "CONFIG['model_config'] = MODEL_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-pUW649gfzA"
   },
   "source": [
    "Write a function that builds the datasets for the model.  It will load the data, handle batching, and generate projections for the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unYlUYXq119f"
   },
   "outputs": [],
   "source": [
    "from layers import base_layers\n",
    "from layers import projection_layers\n",
    "\n",
    "def build_dataset(mode, inspect=False):\n",
    "  if mode == base_layers.TRAIN:\n",
    "    split = 'train'\n",
    "    count = None\n",
    "  elif mode == base_layers.EVAL:\n",
    "    split = 'test'\n",
    "    count = 1\n",
    "  else:\n",
    "    raise ValueError('mode={}, must be TRAIN or EVAL'.format(mode))\n",
    "\n",
    "  batch_size = CONFIG['batch_size']\n",
    "  if inspect:\n",
    "    batch_size = 1\n",
    "\n",
    "  # Convert examples from their dataset format into the model format.\n",
    "  def process_input(features):\n",
    "    # Generate the projection for each comment_text input.  The final tensor \n",
    "    # will have the shape [batch_size, number of tokens, feature size].\n",
    "    # Additionally, we generate a tensor containing the number of tokens for\n",
    "    # each comment_text (seq_length).  This is needed because the projection\n",
    "    # tensor is a full tensor, and we are not using EOS tokens.\n",
    "    text = features['comment_text']\n",
    "    text = tf.reshape(text, [batch_size])\n",
    "    projection_layer = projection_layers.ProjectionLayer(MODEL_CONFIG, mode)\n",
    "    projection, seq_length = projection_layer(text)\n",
    "\n",
    "    # Convert the labels into an indicator tensor, using the LABELS indices.\n",
    "    label = tf.stack([features[label] for label in LABELS], axis=-1)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    label = tf.reshape(label, [batch_size, len(LABELS)])\n",
    "\n",
    "    model_features = ({'projection': projection, 'sequence_length': seq_length}, label)\n",
    "\n",
    "    if inspect:\n",
    "      model_features = (model_features[0], model_features[1], features)\n",
    "\n",
    "    return model_features\n",
    "\n",
    "  ds = tfds.load('goemotions', split=split)\n",
    "  ds = ds.repeat(count=count)\n",
    "  ds = ds.shuffle(buffer_size=batch_size * 2)\n",
    "  ds = ds.batch(batch_size, drop_remainder=True)\n",
    "  ds = ds.map(process_input,\n",
    "              num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "              deterministic=False)\n",
    "  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "  return ds\n",
    "\n",
    "train_dataset = build_dataset(base_layers.TRAIN)\n",
    "test_dataset = build_dataset(base_layers.EVAL)\n",
    "inspect_dataset = build_dataset(base_layers.TRAIN, inspect=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQmYWg6ivCHS"
   },
   "source": [
    "Print a batch of examples in model format.  This will consist of:\n",
    "* the projection tensors (projection and seq_length)\n",
    "* the label tensor (second tuple value)\n",
    "\n",
    "The projection tensor is a **[batch size, max_seq_length, feature_size]** floating point tensor.  The **[b, i]** vector is a feature vector of the **i**th token of the **b**th comment_text.  The rest of the tensor is zero-padded, and the\n",
    "seq_length tensor indicates the number of features vectors for each comment_text.\n",
    "\n",
    "The label tensor is an indicator tensor of the set of true labels for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OyK7rjTvBjF"
   },
   "outputs": [],
   "source": [
    "example = next(iter(train_dataset))\n",
    "print(\"inputs = {}\".format(example[0]))\n",
    "print(\"labels = {}\".format(example[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytMQHT5Kd7A_"
   },
   "source": [
    "In this version of the dataset, the original example has been added as the third element of the tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29EzRoCfI91r"
   },
   "outputs": [],
   "source": [
    "example = next(iter(inspect_dataset))\n",
    "print(\"inputs = {}\".format(example[0]))\n",
    "print(\"labels = {}\".format(example[1]))\n",
    "print(\"original example = {}\".format(example[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLDbHTIvvX11"
   },
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqUTa7wXsHoO"
   },
   "source": [
    "First we define a function to build the model.  We vary the model inputs depending on task.  For training and evaluation, we'll take the projection and sequence length as inputs.  Otherwise, we'll take strings as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "erEiNX3ToLZ1"
   },
   "outputs": [],
   "source": [
    "from models import prado\n",
    "\n",
    "def build_model(mode):\n",
    "  # First we define our inputs.\n",
    "  inputs = []\n",
    "  if mode == base_layers.TRAIN or mode == base_layers.EVAL:\n",
    "    # For TRAIN and EVAL, we'll be getting dataset examples,\n",
    "    # so we'll get projections and sequence_lengths.\n",
    "    projection = tf.keras.Input(\n",
    "        shape=(MODEL_CONFIG['max_seq_len'], MODEL_CONFIG['feature_size']),\n",
    "        name='projection',\n",
    "        dtype='float32')\n",
    "\n",
    "    sequence_length = tf.keras.Input(\n",
    "        shape=(), name='sequence_length', dtype='float32')\n",
    "    inputs = [projection, sequence_length]\n",
    "  else:\n",
    "    # Otherwise, we get string inputs which we need to project.\n",
    "    input = tf.keras.Input(shape=(), name='input', dtype='string')\n",
    "    projection_layer = projection_layers.ProjectionLayer(MODEL_CONFIG, mode)\n",
    "    projection, sequence_length = projection_layer(input)\n",
    "    inputs = [input]\n",
    "\n",
    "  # Next we add the model layer.\n",
    "  model_layer = prado.Encoder(MODEL_CONFIG, mode)\n",
    "  logits = model_layer(projection, sequence_length)\n",
    "\n",
    "  # Finally we add an activation layer.\n",
    "  if MODEL_CONFIG['multilabel']:\n",
    "    activation = tf.keras.layers.Activation('sigmoid', name='predictions')\n",
    "  else:\n",
    "    activation = tf.keras.layers.Activation('softmax', name='predictions')\n",
    "  predictions = activation(logits)\n",
    "\n",
    "  model = tf.keras.Model(\n",
    "      inputs=inputs,\n",
    "      outputs=[predictions])\n",
    "  \n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caHpK9Htv40g"
   },
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xM-2R38kogo"
   },
   "outputs": [],
   "source": [
    "# Remove any previous training data.\n",
    "!rm -rf model\n",
    "\n",
    "model = build_model(base_layers.TRAIN)\n",
    "\n",
    "# Create the optimizer.\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=CONFIG['learning_rate'],\n",
    "    decay_rate=CONFIG['learning_rate_decay_rate'],\n",
    "    decay_steps=CONFIG['learning_rate_decay_steps'],\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Define the loss function.\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "epochs = int(CONFIG['train_steps'] / CONFIG['save_checkpoints_steps'])\n",
    "model.fit(\n",
    "    x=train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_dataset,\n",
    "    steps_per_epoch=CONFIG['save_checkpoints_steps'])\n",
    "\n",
    "model.save_weights('model/model_checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hdbXBs0g3oX"
   },
   "source": [
    "Load a training checkpoint and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1qc9GNtF3s5"
   },
   "outputs": [],
   "source": [
    "model = build_model(base_layers.EVAL)\n",
    "\n",
    "# Define metrics over each category.\n",
    "metrics = []\n",
    "for i, label in enumerate(LABELS):\n",
    "  metric = tf.keras.metrics.Precision(\n",
    "      thresholds=[0.5],\n",
    "      class_id=i,\n",
    "      name='precision@0.5/{}'.format(label))\n",
    "  metrics.append(metric)\n",
    "  metric = tf.keras.metrics.Recall(\n",
    "      thresholds=[0.5],\n",
    "      class_id=i,\n",
    "      name='recall@0.5/{}'.format(label))\n",
    "  metrics.append(metric)\n",
    "\n",
    "# Define metrics over the entire task.\n",
    "metric = tf.keras.metrics.Precision(thresholds=[0.5], name='precision@0.5/all')\n",
    "metrics.append(metric)\n",
    "metric = tf.keras.metrics.Recall(thresholds=[0.5], name='recall@0.5/all')\n",
    "metrics.append(metric)\n",
    "\n",
    "model.compile(metrics=metrics)\n",
    "model.load_weights('model/model_checkpoint')\n",
    "result = model.evaluate(x=test_dataset, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Namwa3enwQBc"
   },
   "source": [
    "Print evaluation metrics for the model, as well as per emotion label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l420PosisfXN"
   },
   "outputs": [],
   "source": [
    "for label in LABELS:\n",
    "  precision_key = 'precision@0.5/{}'.format(label)\n",
    "  recall_key = 'recall@0.5/{}'.format(label)\n",
    "  if precision_key in result and recall_key in result:\n",
    "    print('{}: (precision@0.5: {}, recall@0.5: {})'.format(\n",
    "        label, result[precision_key], result[recall_key]))\n",
    "    \n",
    "precision_key = 'precision@0.5/all'\n",
    "recall_key = 'recall@0.5/all'\n",
    "if precision_key in result and recall_key in result:\n",
    "  print('all: (precision@0.5: {}, recall@0.5: {})'.format(\n",
    "      result[precision_key], result[recall_key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZSWnwTMqZ5f"
   },
   "source": [
    "## Suggest Emojis using an Emotion Prediction model\n",
    "\n",
    "In this section, we apply the Emotion Prediction model trained above to suggest emojis relevant to input text.\n",
    "\n",
    "Refer to our [GoEmotions Model Card](https://github.com/google-research/google-research/blob/master/goemotions/goemotions_model_card.pdf) for additional uses of the model and considerations and limitations for using the GoEmotions data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aybpGQV1qr8I"
   },
   "source": [
    "Map each emotion label to a relevant emoji:\n",
    "* Emotions are subtle and multi-faceted. In many cases, no one emoji can truely capture the full complexity of the human experience behind each emotion. \n",
    "* For the purpose of this exercise, we will select an emoji that captures at least one facet that is conveyed by an emotion label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rh_3y7OL7JG_"
   },
   "source": [
    "Select sample inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdD6xPpn7Mjm"
   },
   "outputs": [],
   "source": [
    "PREDICT_TEXT = [\n",
    "  b'Good for you!',\n",
    "  b'Happy birthday!',\n",
    "  b'I love you.',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vavivya6hGw0"
   },
   "source": [
    "Run inference for the selected examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJ6iyLlLo5-3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = build_model(base_layers.PREDICT)\n",
    "model.load_weights('model/model_checkpoint')\n",
    "\n",
    "for text in PREDICT_TEXT:\n",
    "  results = model.predict(x=[text])\n",
    "  print('')\n",
    "  print('{}:'.format(text))\n",
    "  labels = np.flip(np.argsort(results[0]))\n",
    "  for x in range(3):\n",
    "    label = LABELS[labels[x]]\n",
    "    #label = EMOJI_MAP[label] if EMOJI_MAP[label] else label\n",
    "    print('{}: {}'.format(label, results[0][labels[x]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Emotion Text Analyses on Reddit posts from the Ukrain and Russian war </h1>\n",
    "\n",
    "In this section, we will import a relevant dataset from the subreddit on the UkrainRusian conflict. We will attempt to analyse if a certain emotion correlates to a given response expressed in the number of upvotes of a given post.\n",
    "\n",
    "First we import the relevant modules:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# loss functions for today\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# stuff for evaluating classifiers\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt # for displaying a pretty confusion matrix\n",
    "\n",
    "\n",
    "# dummy models for comparison\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# regression models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we import the data and create our dataframe.\n",
    "\n",
    "We will drop all posts with a nan value in the score and title column as these are outliers and will skew our data.\n",
    "We will drop all posts with a score of over 10,000 as these are outliers and will skew our data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 title  score      id  \\\n3    I'm safe, fifteen hours with a shovel in my ha...   1519  y39tem   \n4    this is my shell. there are many like it. but ...    339  y3hhep   \n5    Aleksey Martynov, a mobilized Moscow governmen...    608  y3897p   \n6    The head of the collaborationist Kherson milit...    132  y3i9wm   \n7    Jackie and Vladyslav served together in Mariup...    134  y3hb4n   \n..                                                 ...    ...     ...   \n976  Lieutenant Sergei Didorenko & Senior Lieutenan...    228  xvp4c8   \n977  Ukrainian forces blew up a Russian ammo cache ...    153  xvp2i0   \n978  Ka-52 pilot Captain Aleksey Belonozhko has bee...    304  xvp1gi   \n979      Current frontlines according to Michael McKay    148  xvp0x9   \n980  Russian Commander of a tank company, Negmonov ...    277  xvoz4d   \n\n                subreddit                                    url  \\\n3    RussiaUkraineWar2022    https://i.redd.it/m4us0z3gzmt91.jpg   \n4    RussiaUkraineWar2022    https://i.redd.it/t9c4v2iqmot91.jpg   \n5    RussiaUkraineWar2022    https://i.redd.it/ooi517zuomt91.jpg   \n6    RussiaUkraineWar2022        https://v.redd.it/zpoe97uftot91   \n7    RussiaUkraineWar2022        https://v.redd.it/54cc5oj7lot91   \n..                    ...                                    ...   \n976  RussiaUkraineWar2022  https://www.reddit.com/gallery/xvp4c8   \n977  RussiaUkraineWar2022        https://v.redd.it/3xd2ekcthur91   \n978  RussiaUkraineWar2022    https://i.redd.it/t6sxzwxlhur91.jpg   \n979  RussiaUkraineWar2022  https://www.reddit.com/gallery/xvp0x9   \n980  RussiaUkraineWar2022    https://i.redd.it/405ja4n7hur91.jpg   \n\n     num_comments                                           body       created  \n3             160  If you have a desire to help me, write to me.  1.665695e+09  \n4              25                                            NaN  1.665714e+09  \n5              92                                            NaN  1.665691e+09  \n6              26                                            NaN  1.665717e+09  \n7               7                                            NaN  1.665714e+09  \n..            ...                                            ...           ...  \n976            20                                            NaN  1.664914e+09  \n977             7                                            NaN  1.664914e+09  \n978            17                                            NaN  1.664914e+09  \n979            17                                            NaN  1.664914e+09  \n980            11                                            NaN  1.664914e+09  \n\n[3772 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>score</th>\n      <th>id</th>\n      <th>subreddit</th>\n      <th>url</th>\n      <th>num_comments</th>\n      <th>body</th>\n      <th>created</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>I'm safe, fifteen hours with a shovel in my ha...</td>\n      <td>1519</td>\n      <td>y39tem</td>\n      <td>RussiaUkraineWar2022</td>\n      <td>https://i.redd.it/m4us0z3gzmt91.jpg</td>\n      <td>160</td>\n      <td>If you have a desire to help me, write to me.</td>\n      <td>1.665695e+09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>this is my shell. there are many like it. but ...</td>\n      <td>339</td>\n      <td>y3hhep</td>\n      <td>RussiaUkraineWar2022</td>\n      <td>https://i.redd.it/t9c4v2iqmot91.jpg</td>\n      <td>25</td>\n      <td>NaN</td>\n      <td>1.665714e+09</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Aleksey Martynov, a mobilized Moscow governmen...</td>\n      <td>608</td>\n      <td>y3897p</td>\n      <td>RussiaUkraineWar2022</td>\n      <td>https://i.redd.it/ooi517zuomt91.jpg</td>\n      <td>92</td>\n      <td>NaN</td>\n      <td>1.665691e+09</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The head of the collaborationist Kherson milit...</td>\n      <td>132</td>\n      <td>y3i9wm</td>\n      <td>RussiaUkraineWar2022</td>\n      <td>https://v.redd.it/zpoe97uftot91</td>\n      <td>26</td>\n      <td>NaN</td>\n      <td>1.665717e+09</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Jackie and Vladyslav served together in Mariup...</td>\n      <td>134</td>\n      <td>y3hb4n</td>\n      <td>RussiaUkraineWar2022</td>\n      <td>https://v.redd.it/54cc5oj7lot91</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>1.665714e+09</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>976</th>\n      <td>Lieutenant Sergei Didorenko &amp; Senior Lieutenan...</td>\n      <td>228</td>\n      <td>xvp4c8</td>\n      <td>RussiaUkraineWar2022</td>\n      <td>https://www.reddit.com/gallery/xvp4c8</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>1.664914e+09</td>\n    </tr>\n    <tr>\n      <th>977</th>\n      <td>Ukrainian forces blew up a Russian ammo cache ...</td>\n      <td>153</td>\n      <td>xvp2i0</td>\n      <td>RussiaUkraineWar2022</td>\n      <td>https://v.redd.it/3xd2ekcthur91</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>1.664914e+09</td>\n    </tr>\n    <tr>\n      <th>978</th>\n      <td>Ka-52 pilot Captain Aleksey Belonozhko has bee...</td>\n      <td>304</td>\n      <td>xvp1gi</td>\n      <td>RussiaUkraineWar2022</td>\n      <td>https://i.redd.it/t6sxzwxlhur91.jpg</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>1.664914e+09</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>Current frontlines according to Michael McKay</td>\n      <td>148</td>\n      <td>xvp0x9</td>\n      <td>RussiaUkraineWar2022</td>\n      <td>https://www.reddit.com/gallery/xvp0x9</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>1.664914e+09</td>\n    </tr>\n    <tr>\n      <th>980</th>\n      <td>Russian Commander of a tank company, Negmonov ...</td>\n      <td>277</td>\n      <td>xvoz4d</td>\n      <td>RussiaUkraineWar2022</td>\n      <td>https://i.redd.it/405ja4n7hur91.jpg</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>1.664914e+09</td>\n    </tr>\n  </tbody>\n</table>\n<p>3772 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('./Datasets/hot_posts.csv')\n",
    "df2 = pd.read_csv('./Datasets/top_posts.csv')\n",
    "df3 = pd.read_csv('./Datasets/controversial_posts.csv')\n",
    "df4 = pd.read_csv('./Datasets/new_posts.csv')\n",
    "dfMerge = [df1, df2, df3, df4]\n",
    "df = pd.concat(dfMerge)\n",
    "df.dropna(subset=['score'], inplace=True)\n",
    "df.dropna(subset=['title'], inplace=True)\n",
    "df.drop(df[df['score'] > 10000].index, axis=0, inplace=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seb_R\\AppData\\Local\\Temp\\ipykernel_15460\\3876251204.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['title','score']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 title  score\n3    I'm safe, fifteen hours with a shovel in my ha...   1519\n4    this is my shell. there are many like it. but ...    339\n5    Aleksey Martynov, a mobilized Moscow governmen...    608\n6    The head of the collaborationist Kherson milit...    132\n7    Jackie and Vladyslav served together in Mariup...    134\n..                                                 ...    ...\n976  Lieutenant Sergei Didorenko & Senior Lieutenan...    228\n977  Ukrainian forces blew up a Russian ammo cache ...    153\n978  Ka-52 pilot Captain Aleksey Belonozhko has bee...    304\n979      Current frontlines according to Michael McKay    148\n980  Russian Commander of a tank company, Negmonov ...    277\n\n[3772 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>I'm safe, fifteen hours with a shovel in my ha...</td>\n      <td>1519</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>this is my shell. there are many like it. but ...</td>\n      <td>339</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Aleksey Martynov, a mobilized Moscow governmen...</td>\n      <td>608</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The head of the collaborationist Kherson milit...</td>\n      <td>132</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Jackie and Vladyslav served together in Mariup...</td>\n      <td>134</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>976</th>\n      <td>Lieutenant Sergei Didorenko &amp; Senior Lieutenan...</td>\n      <td>228</td>\n    </tr>\n    <tr>\n      <th>977</th>\n      <td>Ukrainian forces blew up a Russian ammo cache ...</td>\n      <td>153</td>\n    </tr>\n    <tr>\n      <th>978</th>\n      <td>Ka-52 pilot Captain Aleksey Belonozhko has bee...</td>\n      <td>304</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>Current frontlines according to Michael McKay</td>\n      <td>148</td>\n    </tr>\n    <tr>\n      <th>980</th>\n      <td>Russian Commander of a tank company, Negmonov ...</td>\n      <td>277</td>\n    </tr>\n  </tbody>\n</table>\n<p>3772 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop all columns except for title and score\n",
    "\n",
    "df.drop(df.columns.difference(['title','score']), 1, inplace=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 title  score  emotion\n3    I'm safe, fifteen hours with a shovel in my ha...   1519        0\n4    this is my shell. there are many like it. but ...    339        0\n5    Aleksey Martynov, a mobilized Moscow governmen...    608        0\n6    The head of the collaborationist Kherson milit...    132        0\n7    Jackie and Vladyslav served together in Mariup...    134        0\n..                                                 ...    ...      ...\n976  Lieutenant Sergei Didorenko & Senior Lieutenan...    228        0\n977  Ukrainian forces blew up a Russian ammo cache ...    153        0\n978  Ka-52 pilot Captain Aleksey Belonozhko has bee...    304        0\n979      Current frontlines according to Michael McKay    148        0\n980  Russian Commander of a tank company, Negmonov ...    277        0\n\n[3772 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>score</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>I'm safe, fifteen hours with a shovel in my ha...</td>\n      <td>1519</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>this is my shell. there are many like it. but ...</td>\n      <td>339</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Aleksey Martynov, a mobilized Moscow governmen...</td>\n      <td>608</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The head of the collaborationist Kherson milit...</td>\n      <td>132</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Jackie and Vladyslav served together in Mariup...</td>\n      <td>134</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>976</th>\n      <td>Lieutenant Sergei Didorenko &amp; Senior Lieutenan...</td>\n      <td>228</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>977</th>\n      <td>Ukrainian forces blew up a Russian ammo cache ...</td>\n      <td>153</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>978</th>\n      <td>Ka-52 pilot Captain Aleksey Belonozhko has bee...</td>\n      <td>304</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>Current frontlines according to Michael McKay</td>\n      <td>148</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>980</th>\n      <td>Russian Commander of a tank company, Negmonov ...</td>\n      <td>277</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3772 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new column called emotion and set all values to 0\n",
    "\n",
    "df['emotion'] = 0\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[\"I'm safe, fifteen hours with a shovel in my hands and I have my own little house\",\n 'this is my shell. there are many like it. but this one is mine.',\n 'Aleksey Martynov, a mobilized Moscow government official, returned from Ukraine. He was mobilized on September 23, and on October 10 he died.',\n 'The head of the collaborationist Kherson military–civilian administration in Russian-occupied Ukraine (Volodymyr Saldo), who was holding Putler\\'s hand and yelling \"Russia is here for ever!\" two weeks ago, is now officially asking the Kremlin to help him evacuate his fellow collaborators.',\n 'Jackie and Vladyslav served together in Mariupol. Vlad managed to get out, reluctantly leaving Jackie at Azovstal. She came home (15 km away!) on her own. It took 4 months to get Jackie out of Mariupol. Now she and Vlad serve in Kharkiv region.',\n 'RUSSIAN civilians have been urged to flee from Kherson as Ukrainian fighters are only 12 miles from reclaiming the occupied city.',\n 'Mobilized Muscovites sent to front without training and suffered heavy losses',\n 'Pro-Russian German protesters chant “Nazis, get the hell out” toward the Ukrainian refugees who dared to show up to counter-protest in Leipzig. There is a 5th column active in large parts of Europe. We must remain aware of that fact.',\n 'The Minister of National Defense, Mariusz Błaszczak, said: Poland has been supporting Ukraine from the very start of the war. We are doing this because we want to border independent Ukraine, not Russia. Security of Poland and NATO’s Eastern flank depends on the situation in Ukraine.',\n 'Russian Tiktok Army getting Destroyed by Ukrainian Force.']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn the first 10 instances of the title column into a list of strings called PREDICT_TEXT\n",
    "\n",
    "PREDICT_TEXT = df['title'].head(10).tolist()\n",
    "PREDICT_TEXT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Run inference for the selected examples:\n",
    "\n",
    "model = build_model(base_layers.PREDICT)\n",
    "model.load_weights('model/model_checkpoint')\n",
    "\n",
    "for text in PREDICT_TEXT:\n",
    "  results = model.predict(x=[text])\n",
    "  print('')\n",
    "  print('{}:'.format(text))\n",
    "  labels = np.flip(np.argsort(results[0]))\n",
    "  for x in range(3):\n",
    "    label = LABELS[labels[x]]\n",
    "    #label = EMOJI_MAP[label] if EMOJI_MAP[label] else label\n",
    "    print('{}: {}'.format(label, results[0][labels[x]]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Insert the predicted emotion into the emotion column\n",
    "\n",
    "for text in PREDICT_TEXT:\n",
    "  results = model.predict(x=[text])\n",
    "  labels = np.flip(np.argsort(results[0]))\n",
    "  label = LABELS[labels[0]]\n",
    "  df.loc[df['title'] == text, 'emotion'] = label\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
